# âš¡ Quick LLM Reference Card

## ğŸ¯ Your Current Setup

```
âœ… Llama 3.2 (2.0 GB)  - Primary, best overall
âœ… Llama 3.1 (4.9 GB)  - Backup
âœ… CodeLlama (3.8 GB)  - Coding tasks
```

## ğŸŒŸ Top Recommendations to Add

| Model | Size | Install Command | Use Case |
|-------|------|-----------------|----------|
| **Mistral** | 4.1 GB | `ollama pull mistral` | Fast, reliable ğŸŸ¢ |
| **DeepSeek-R1** | 7-8 GB | `ollama pull deepseek-r1` | Best reasoning âš ï¸ |
| **Phi-3** | 3.8 GB | `ollama pull phi3` | Ultra-fast âš¡ |

## ğŸš¦ Quick Decision Guide

**Need best accuracy?** â†’ DeepSeek-R1  
**Need speed?** â†’ Llama 3.2 (you have it!) or Phi-3  
**Need reliability?** â†’ Mistral  
**Government/sensitive?** â†’ Avoid DeepSeek, use Mistral/Llama  

## ğŸ“¦ Quick Install All

```bash
ollama pull mistral      # Fast, reliable
ollama pull phi3         # Ultra-fast
ollama pull gemma2       # Balanced
ollama pull deepseek-r1  # Best reasoning (âš ï¸ regulatory concerns)
```

## ğŸ” Check What You Have

```bash
ollama list              # Show installed
ollama search deepseek   # Search models
ollama show mistral      # Model info
```

## âš¡ Test a Model

```bash
ollama run llama3.2 "Classify this content for safety"
ollama run mistral "Is this spam?"
```

## ğŸ“Š Size Guide

- **< 4 GB**: Llama 3.2, Phi-3, Mistral
- **4-8 GB**: Llama 3.1, Gemma 2, Qwen 2.5
- **> 8 GB**: DeepSeek-R1, Large models

---

**Full Guide**: `docs/guides/POPULAR_LOCAL_LLMS.md`

