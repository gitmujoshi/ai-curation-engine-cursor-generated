# AI Curation Engine - Ollama Service Dockerfile
# For Render.com background worker deployment

FROM ollama/ollama:latest

# Metadata
LABEL description="Ollama Server for AI Curation Engine"
LABEL version="1.0"

# Environment variables
ENV OLLAMA_HOST=0.0.0.0
ENV OLLAMA_ORIGINS="*"

# Expose Ollama API port
EXPOSE 11434

# Health check - verify Ollama is responding
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:11434/api/tags || exit 1

# Start Ollama server
CMD ["ollama", "serve"]

